# Flood Risk Management in the IJssel River
## Decision-Making under Deep Uncertainty through Modeling

Prepared for EPA141A by Group 10. 

|    Members             | Student Number |
| ---------------------- | -------------- |
| Nelene Augustinus      |   5404916      |
| Floor Broekman         |   5333806      |
| Nikhil Daswani         |   5049954      |
| Milan Moleman          |   5415764      |


## Contents
- [Flood Risk Management in the IJssel River](#flood-risk-management-in-the-ijssel-river)
  - [Decision-Making under Deep Uncertainty through Modeling](#decision-making-under-deep-uncertainty-through-modeling)
  - [Contents](#contents)
  - [File Structure](#file-structure)
    - [Directories](#directories)
    - [Model \& Workbench Files](#model--workbench-files)
    - [Experimentation \& Analysis Files (\& Usage)](#experimentation--analysis-files--usage)
    - [Other Files](#other-files)
  - [Modeling Workflow](#modeling-workflow)
    - [Part 1: Uncertainty Analysis (Open Exploration)](#part-1-uncertainty-analysis-open-exploration)
    - [Part 2: Scenario Discovery \& Selection (Open Exploration)](#part-2-scenario-discovery--selection-open-exploration)
        - [Part 2a: Visual Analysis \& Scenario Discovery (Open Exploration)](#part-2a-visual-analysis--scenario-discovery-open-exploration)
        - [Part 2b: Scenario Selection](#part-2b-scenario-selection)
    - [Part 3: Multi-Scenario, Multi-Objective Robust Decision-Making (Multi-scenario MORDM)](#part-3-multi-scenario-multi-objective-robust-decision-making-multi-scenario-mordm)
        - [Part 3a: Generative Algorithm Policy Search](#part-3a-generative-algorithm-policy-search)
        - [Part 3b: Convergence Testing, Initial Policy Filtering, Robustness of Policies, Tradeoff Analysis](#part-3b-convergence-testing-initial-policy-filtering-robustness-of-policies-tradeoff-analysis)


## File Structure

An annotated directory `tree` is provided below, outlining the purpose of each category and highlighting specific individual files.

```
# Directories
├── data/
├── images/
├    ├── opt/
├    ├── prim/
├    └──  sobol/
├── results/
├    ├── op100/
├    ├── op150/
├    ├── op200/
├    ├── op150_1e4/
├    └──  op150_1e5/
# Base Model Files -- Untouched
├── __init__.py
├── dike_model_function.py
├── funs_dikes.py
├── funs_economy.py
├── funs_generate_network.py
├── funs_hydrostat.py
# Provided Workbench Files -- Unedited
├── problem_formulation.py
├── dike_model_simulation.py
# Experimentation & Analysis Files
# (in order of first use in modeling workflow)
├── dike_model_prim_analysis.ipynb
├── dike_model_visual_analysis.ipynb
├── dike_model_sobol_analysis.ipynb
├── scenario_selection.py
├── dike_model_scenario_selection.ipynb
├── dike_model_multi_scenario_MORDM.py
├── dike_model_multi_scenario_MORDM_reevaluation.py
├── dike_model_multi_scenario_MORDM.ipynb
# Other
├── requirements.txt
└── README.md

```

### Directories
* [archives/](archives) contains a history of the full run from the Optimization process, for reference and for use in checking whether the generative algorithm converged
* [data/](data) is a folder containing data used by the base model, without any modifications.
* [results/](results) contains all the output files generated during our analysis process, primarily consisting of CSV files or compressed tarballs of additional CSV files. There is a table in the [Modeling Workflow](#modeling-workflow) that describes these files and specifies their originating file. **NOTE**: Running our analysis will overwrite these files. It also contains a complete history of the run from the Optimization process, intended for reference and for verifying whether the generative algorithm converged.
  * [opt100/](opt100) contains all the optimizations that were simulated for optimizer opt100.
  * [opt150/](opt150) contains all the optimizations that were simulated for optimizer opt150.
  * [opt200/](opt200) contains all the optimizations that were simulated for optimizer opt200.
  * [opt50_1e4/](opt50_1e4) contains all the optimizations that were simulated for optimizer opt50 with an epsilon value of 10.000.
  * [opt50_1e5/](opt50_1e5) contains all the optimizations that were simulated for optimizer opt50 with an epsilon value of 100.000.
* [images/](images) contains all plots and diagrams generated by the code in our analysis files.
  * [opt/](opt) contains all the plots for the optimizations.
  * [prim/](prim) contains all the plots for the PRIM analysis.
  * [sobol/](sobol) contains all the plots for the Global Sensitivity Analysis (Sobol + Feature Scoring).  

### Model & Workbench Files
* The IJssel River model files were left untouched, as our client's needs did not require any modifications or extensions to the provided model.
* The provided workbench interface file, [problem_formulation.py](problem_formulation.py), was not modified

### Experimentation & Analysis Files (& Usage)
* These files make up the bulk of our work as modellers and analysts. They follow a linear pipeline process with an opportunity to plug final results back into the start of the process to iterate on scenario and policy discovery. 
* Unfortunately, we did not have the time to create one combined runfile that performs the entire process from start to finish.
* **These files are what to run to replicate our results. Their usage is described in [Modeling Workflow](#modeling-workflow), below.**

* These files constitute the majority of our work as modelers and analysts. They follow a linear process. The opportunity also exists to feed the final results back into the start of the process to iterate on scenario and policy discovery.
* Unfortunately, we did not have the time to create a single combined runfile that performs the entire process from start to finish.
* **These files should be run to replicate our results. Their usage is described in [Modeling Workflow](#modeling-workflow), below.**

### Other Files
* We include a requirements file that includes all the required and relevant packages to run the files included in this repository. 
* You are currently reading the README.
  
## Modeling Workflow
As mentioned, our modeling workflow is quite linear, with opportunities to feed results back to the starting point from multiple stages along the way. This section will describe the workflow and provide usage instructions for each file used at each step.



### Part 1: Uncertainty Analysis (Open Exploration)

**Files:** [dike_model_prim_analysis.ipynb](dike_model_prim_analysis.ipynb)

**Purpose & Output:** This component generates graphs that illustrate the significance of different uncertainties and levers on the overall performance and outcomes of the IJssel River model.

* Global Sensitivity Analysis: This involves creating multiple plots that visualize metrics from Sobol analysis, with a specific focus on S1, ST, and confidence intervals across various outcomes.
* Feature Scoring: This process generates a heatmap that quantifies the correlation between each uncertainty and the outcomes of interest.

**Instructions:** Open as Jupyter Notebooks and read results, or start a kernel and run from where results are loaded, until the bottom. **NOTE** Do not run the cell where experiments are perfomed as this may take quiet some time to execute.

**Required Input:** A valid experimental results file, likely the `sobol_results_problem2.tar.gz` or file 

### Part 2: Scenario Discovery & Selection (Open Exploration)


##### Part 2a: Visual Analysis & Scenario Discovery (Open Exploration)

**File:** **File:** [dike_model_prim_analysis.ipynb](dike_model_prim_analysis.ipynb) & [dike_model_visual_analysis.ipynb](dike_model_visual_analysis.ipynb)

**Purpose & Output:** 

* Generates graphs illustrating the parts of the outcome space and uncertainty space of the experiments conducted.
* Makes use of PRIM to identify a subspace within the model's uncertainty space that effectively represents the "region of concern." Scenarios falling within this subspace are likely to result in undesirable outcomes.

**Instructions:** Open as a Jupyter Notebook and read results, or start a kernel and run from top to bottom.

**Required Input:** A valid experimental (open exploration) results file, likely the `openexplor_problem1.tar.gz`, `openexplor_problem2.tar.gz` or `openexplor_problem3.tar.gz` file.

##### Part 2b: Scenario Selection

**File:** [dike_model_scenario_selection.ipynb](dike_model_scenario_selection.ipynb)

**Purpose & Output:** Samples 50.000 combinations of the filtered (post-PRIM) scenarios to identify a set of four scenarios that maximize diversity in terms of certain model outcomes.
* All sampled combinations include the "worst-case" scenario studied, which is the scenario that resulted in the greatest amount of deaths in Dike Rings 1 through 3 under the base case scenario, where nothing is done and no policies or mitigation measures are implemented.
* Diversity is evaluated based on the following outcomes: deaths to Dike Ring 1 through 3, combined damages to Dike Rings 1 & 2, and total damages. The goal is to find scenarios that cause disproportionately high amount of deaths to each of the regions.
* Outputs the selected set of scenarios to the file ([scenario_selection.tar.gz](results/scenario_selection.tar.gz)).

**Instructions:** Open as a Jupyter Notebook and read results, or start a kernel and run from top to bottom.

**Required Input:** A combined and PRIM-filtered experimental results table, such as `prim_problem3.tar.gz`.

### Part 3: Multi-Scenario, Multi-Objective Robust Decision-Making (Multi-scenario MORDM)


##### Part 3a: Generative Algorithm Policy Search

**File:** [dike_model_multi_scenario_MORDM.py](dike_model_multi_scenario_MORDM.py)

**Purpose & Output:** 
* For each scenario selected in Step 2b, execute a generative algorithm three times with different seeds to discover and evaluate policies optimizing the chosen problem formulation's outcomes.
* Save output files named `optimization_3_{scenario.name}_seed_{i}.tar.gz` and `optimization_3_{scenario.name}_convergence.png` in directories `results/` and `images/`, respectively. These files contain:
  * Results: Policies found by the algorithm alongside model outcomes computed for the corresponding scenario.
  * Images: Plots indicating `epsilon_progress`, showing whether the generative algorithm converged to a final set of policies.

**Instructions:** 

```
python dike_model_multi_scenario_MORDM.py`
```

**Required Input:** A table of scenarios in `scenario_selection.tar.gz`, which was generated in Step 2b.


##### Part 3b: Convergence Testing, Initial Policy Filtering, Robustness of Policies, Tradeoff Analysis 

**File:** [dike_model_multi_scenario_MORDM.ipynb](dike_model_multi_scenario_MORDM.ipynb),  [`dike_model_multi_scenario_MORDM.py`](dike_model_multi_scenario_MORDM.py) & [`dike_model_multi_scenario_MORDM_reevaluation.py`](dike_model_multi_scenario_MORDM_reevaluation.py)

**Purpose & Output:** 
* Create scenario set using the most diverse scenarios
* Generate Candidate Solutions by creating a function to optimze under a certain scenario
* Testing convergence based on optimizations runs in [`dike_model_multi_scenario_MORDM_reevaluation.py`](dike_model_multi_scenario_MORDM.py) and looking at the different seeds. It evaluates the optimization process carried out in the previous file, by plotting convergence metrics showing how the generative algorithm moved towards optimization. These plots are saved in `images/`.
* Analysis of results per scenario from the 5 scenarios in the scenario set.
* Combining the pareto set of solutions found for each scenario.
* Scaling down the policies and making a selection from pareto set. It filters the discovered policies according to a set of constraints defined to match the the goals of Province of Gelderland.
* Reevaluate the policies in [`dike_model_multi_scenario_MORDM_reevaluation.py`](dike_model_multi_scenario_MORDM_reevaluation.py). Use the EMA Workbench to conduct experiments on the filtered policy set using 1000 random scenarios. Save the results to a file named `reevaluation.opt200.tar.gz` in the respective `opt*` folder. You can also just choose to stay in the notebook and load results that can be found in `results/opt200/` as `reevaluation_opt200.tar.gz`.
* Trade-off Analysis is conducted by looking at multiple robustness metrices. Computes robustness metrics based on the experiment results obtained in the previous step. The main metric is signal-to-noise ratio. The plots generated for the tradeoff analysis are saved as `signal_to_noise_min.png` and `signal_to_noise_min.all` under `images/opt/`.
* Lastly an overview of the policies is shown, and a table is created which shows tradeoffs for each relevant policy and the outcomes of interest. 

**Instructions:** 
**IMPORTANT NOTE:** For these files to work, it is important to modify the source code of EMA_workbench. This is done in the directory `em_framework/`, within the `optimization.py`. After `line 889` the following code should be added: 
```
solutions = []
for index, row in archive.iterrows():
    try:
        decision_variables = row[attr] for attr in problem.parameter_names
```
Open as a Jupyter Notebook and run from top to bottom. **Calculating the diversity of the permutations takes a while, so can be commented out (also comment out the following cell that check the diversity).**

**Required Input:** A set of results from the optimization process, above, and the table of scenarios in `scenario_selection.tar.gz` for which that optimization process was run.
For the reevaluation: 
```
dike_model_multi_scenario_MORDM_reevaluation.py`
```
