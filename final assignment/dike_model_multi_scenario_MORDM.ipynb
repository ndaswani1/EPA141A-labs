{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "from Bartholomew & Kwakkel (2020):\n",
    "\n",
    "\n",
    "2.2. Multi-scenario many-objective robust decision making\n",
    "Multi-scenario MORDM (Watson and Kasprzyk, 2017) is a further\n",
    "refinement of MORDM. The main contribution of MORDM was the\n",
    "use of a MOEA for finding a set of promising candidate solutions\n",
    "which together capture the key trade-offs amongst competing objec\u0002tives. However, this search uses a single reference scenario, and it is\n",
    "unlikely that solutions that are optimal in a given scenario are also\n",
    "optimally robust. Multi-scenario MORDM (Fig. 1(c)) addresses this by\n",
    "performing a search for candidate strategies for several different refer\u0002ence scenarios. The additional scenarios for which search is performed\n",
    "are selected from regions in the deep uncertainty space where candidate\n",
    "solutions found for the first reference scenario are failing to meet their\n",
    "objectives. So, one performs the four MORDM steps, and based on\n",
    "the insights from scenario discovery, additional scenarios are selected\n",
    "for which search is also performed. The goal of this is to build a\n",
    "more diverse set of policy alternatives which are Pareto optimal under\n",
    "different scenarios.\n",
    "The selection of scenarios after the first MORDM iteration is a crit\u0002ical step in multi-scenario MORDM (Eker and Kwakkel, 2018). Watson\n",
    "and Kasprzyk (2017) suggest picking scenarios based on the scenario\n",
    "discovery results. The number of scenarios to select is left to the\n",
    "analyst. Clearly, if the number of scenarios for which a search is\n",
    "conducted increases, the chance of finding solutions that are robust\n",
    "during the re-evaluation also increases. However, this comes at a sub\u0002stantial computational cost. To assist in balancing comprehensiveness\n",
    "and computational cost, while making scenario selection transparent\n",
    "and reproducible, Eker and Kwakkel (2018) present an approach for\n",
    "finding the most policy relevant and maximally diverse set of scenarios.\n",
    "Policy relevance is defined as scenarios that lead to poor outcomes and\n",
    "the diversity criterion is based on Carlsen et al. (2016)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "# A. Many-Objective Robust Decision Making with Multi-Scenario Search",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T15:08:47.391846400Z",
     "start_time": "2024-06-12T15:08:47.366291100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import libraries\n",
    "\n",
    "from ema_workbench import (\n",
    "    Model,\n",
    "    MultiprocessingEvaluator,\n",
    "    ScalarOutcome,\n",
    "    IntegerParameter,\n",
    "    optimize,\n",
    "    Scenario, \n",
    "    save_results,\n",
    "    load_results\n",
    ")\n",
    "from ema_workbench.em_framework import ArchiveLogger\n",
    "from ema_workbench.em_framework.optimization import EpsilonProgress\n",
    "from ema_workbench.util import ema_logging\n",
    "\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.1. Problem formulation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T15:08:43.740585700Z",
     "start_time": "2024-06-12T15:08:36.042871300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "    model, steps = get_model_for_problem_formulation(3)\n",
    "\n",
    "    reference_values = {\n",
    "        \"Bmax\": 175,\n",
    "        \"Brate\": 1.5,\n",
    "        \"pfail\": 0.5,\n",
    "        \"discount rate 0\": 3.5,\n",
    "        \"discount rate 1\": 3.5,\n",
    "        \"discount rate 2\": 3.5,\n",
    "        \"ID flood wave shape\": 4,\n",
    "    }\n",
    "    scen1 = {}\n",
    "\n",
    "    for key in model.uncertainties:\n",
    "        name_split = key.name.split(\"_\")\n",
    "\n",
    "        if len(name_split) == 1:\n",
    "            scen1.update({key.name: reference_values[key.name]})\n",
    "\n",
    "        else:\n",
    "            scen1.update({key.name: reference_values[name_split[1]]})\n",
    "\n",
    "    ref_scenario = Scenario(\"reference\", **scen1)\n",
    "\n",
    "    # determine epsilon\n",
    "    epsilon = [1e3] * len(model.outcomes)\n",
    "    # convergence metrics\n",
    "    convergence_metrics = [ArchiveLogger(\n",
    "        \"./archives\",\n",
    "        [l.name for l in model.levers],\n",
    "        [o.name for o in model.outcomes],\n",
    "        base_filename=\"multiobj_problem3_results.tar.gz\",\n",
    "    ),\n",
    "        EpsilonProgress(),\n",
    "    ]\n",
    "\n",
    "    # number of functions evaluations\n",
    "    nfe = 2  \n",
    "\n",
    "    # multiprocessing\n",
    "    with MultiprocessingEvaluator(model) as evaluator:\n",
    "        results, convergence = evaluator.optimize(\n",
    "            nfe=nfe,\n",
    "            searchover=\"levers\",\n",
    "            epsilons=epsilon,\n",
    "            convergence=convergence_metrics,\n",
    "            reference=ref_scenario,\n",
    "        )"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 44\u001B[0m\n\u001B[0;32m     41\u001B[0m nfe \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m  \n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# multiprocessing\u001B[39;00m\n\u001B[1;32m---> 44\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mMultiprocessingEvaluator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mevaluator\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvergence\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnfe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnfe\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[43m        \u001B[49m\u001B[43msearchover\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlevers\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreference\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mref_scenario\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\EPA141A\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:105\u001B[0m, in \u001B[0;36mBaseEvaluator.__enter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__enter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 105\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minitialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\EPA141A\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\futures_multiprocessing.py:289\u001B[0m, in \u001B[0;36mMultiprocessingEvaluator.initialize\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# check if we need a working directory\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot_dir \u001B[38;5;241m=\u001B[39m determine_rootdir(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_msis)\n\u001B[1;32m--> 289\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool \u001B[38;5;241m=\u001B[39m \u001B[43mmultiprocessing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_processes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    291\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    292\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_msis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_queue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloglevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot_dir\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    293\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaxtasksperchild\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    294\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    295\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_processes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool\u001B[38;5;241m.\u001B[39m_processes\n\u001B[0;32m    296\u001B[0m _logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpool started with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_processes\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m workers\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:119\u001B[0m, in \u001B[0;36mBaseContext.Pool\u001B[1;34m(self, processes, initializer, initargs, maxtasksperchild)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m'''Returns a process pool object'''\u001B[39;00m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Pool\n\u001B[1;32m--> 119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocesses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitializer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxtasksperchild\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:215\u001B[0m, in \u001B[0;36mPool.__init__\u001B[1;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_processes \u001B[38;5;241m=\u001B[39m processes\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 215\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_repopulate_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:306\u001B[0m, in \u001B[0;36mPool._repopulate_pool\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_repopulate_pool\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_repopulate_pool_static\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    307\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_processes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pool\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inqueue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_outqueue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initializer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maxtasksperchild\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m                                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wrap_exception\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:329\u001B[0m, in \u001B[0;36mPool._repopulate_pool_static\u001B[1;34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001B[0m\n\u001B[0;32m    327\u001B[0m w\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m=\u001B[39m w\u001B[38;5;241m.\u001B[39mname\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProcess\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPoolWorker\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    328\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 329\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    330\u001B[0m pool\u001B[38;5;241m.\u001B[39mappend(w)\n\u001B[0;32m    331\u001B[0m util\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madded worker\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    334\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    335\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 336\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     94\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 95\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     97\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.2. Scenario selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is desirable to search for candidate solutions under a variety of scenarios, so that robustness of potential solutions is increased (Eker and Kwakkel, 2018).\n",
    "\n",
    "In this study, our purpose for scenario selection is to find sce\u0002narios that potentially lead to solutions that are more robust when\n",
    "the search phase of MORDM is conducted for each of these sce\u0002narios. Therefore, among the possible scenario selection criteria\n",
    "listed above, we consider policy relevance and diversity as the\n",
    "relevant ones. Policy-relevance is a problem-specific concept that\n",
    "should reflect the decision-making concerns and preferences. In\n",
    "this study, we choose to define policy-relevance with respect to\n",
    "undesirable scenario conditions specified by the median values of\n",
    "the scenario space. Dividing the scenario space at the median\n",
    "values focuses the diversity analysis on a smaller number of policy\u0002relevant scenarios regardless of their distribution. However, we do\n",
    "not propose this as a general way to define policy relevance. For the\n",
    "diversity criterion, we propose to use the specific diversity\n",
    "maximization method introduced by Carlsen et al. (2016b).\n",
    "\n",
    "Following Eker and Kwakkel (2018), scenario selection is conducted in three steps, namely\n",
    "- 1. Scenario generation;\n",
    "- 2. Filtering of policy-relevant scenarios;\n",
    "- 3. Selecting maximally diverse scenarios."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### A.2.1. Scenario generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this step, N scenarios will be generated using randomly sampled values of deep uncertainties and decision levers (Eker and Kwakkel, 2018) ."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T15:08:53.923863200Z",
     "start_time": "2024-06-12T15:08:53.827812700Z"
    }
   },
   "cell_type": "code",
   "source": "scenarios, outcomes = load_results(\"./results/potentialscenarios.tar.gz\")",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results loaded successfully from C:\\Users\\nelen\\EPA141A\\final assignment\\results\\potentialscenarios.tar.gz\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T15:08:56.703554300Z",
     "start_time": "2024-06-12T15:08:56.641692400Z"
    }
   },
   "cell_type": "code",
   "source": "scenarios",
   "outputs": [
    {
     "data": {
      "text/plain": "      A.0_ID flood wave shape    A.1_Bmax A.1_Brate  A.1_pfail    A.2_Bmax  \\\n0                          66  220.340347       1.5   0.277751  317.625580   \n1                          39  287.676115       1.0   0.093811  246.091351   \n2                          50  106.756807      10.0   0.345841  333.340514   \n3                          76   56.356797       1.5   0.189130  196.888090   \n4                         132  298.587312       1.5   0.000580  156.903324   \n...                       ...         ...       ...        ...         ...   \n1546                       89   46.645355       1.0   0.751029  277.455225   \n1547                       62   52.666623       1.0   0.866610   52.132103   \n1548                        7  320.950831       1.5   0.533701  300.887555   \n1549                       49  260.621182       1.5   0.756180  245.847333   \n1550                       35  258.320169       1.0   0.842552   57.433710   \n\n     A.2_Brate  A.2_pfail    A.3_Bmax A.3_Brate  A.3_pfail  ...  \\\n0          1.0   0.246968  114.478228      10.0   0.552078  ...   \n1          1.5   0.271764  101.893796       1.0   0.429600  ...   \n2          1.5   0.745971   82.951536       1.0   0.469837  ...   \n3         10.0   0.057171  280.790547       1.5   0.470550  ...   \n4          1.5   0.970702  232.692672      10.0   0.575071  ...   \n...        ...        ...         ...       ...        ...  ...   \n1546       1.5   0.606332  204.774335      10.0   0.012546  ...   \n1547      10.0   0.671048   73.254758      10.0   0.217036  ...   \n1548       1.0   0.992886  134.842915       1.0   0.166615  ...   \n1549       1.5   0.588074  146.423040       1.0   0.140686  ...   \n1550      10.0   0.934111   43.060722       1.0   0.087416  ...   \n\n      A.3_DikeIncrease 2 A.4_DikeIncrease 0  A.4_DikeIncrease 1  \\\n0                      0                  0                   0   \n1                      0                  0                   0   \n2                      0                  0                   0   \n3                      0                  0                   0   \n4                      0                  0                   0   \n...                  ...                ...                 ...   \n1546                   0                  0                   0   \n1547                   0                  0                   0   \n1548                   0                  0                   0   \n1549                   0                  0                   0   \n1550                   0                  0                   0   \n\n      A.4_DikeIncrease 2 A.5_DikeIncrease 0  A.5_DikeIncrease 1  \\\n0                      0                  0                   0   \n1                      0                  0                   0   \n2                      0                  0                   0   \n3                      0                  0                   0   \n4                      0                  0                   0   \n...                  ...                ...                 ...   \n1546                   0                  0                   0   \n1547                   0                  0                   0   \n1548                   0                  0                   0   \n1549                   0                  0                   0   \n1550                   0                  0                   0   \n\n     A.5_DikeIncrease 2 scenario    policy     model  \n0                     0       23  Policy 0  dikesnet  \n1                     0       40  Policy 0  dikesnet  \n2                     0       65  Policy 0  dikesnet  \n3                     0      125  Policy 0  dikesnet  \n4                     0      155  Policy 0  dikesnet  \n...                 ...      ...       ...       ...  \n1546                  0     4966  Policy 0  dikesnet  \n1547                  0     4967  Policy 0  dikesnet  \n1548                  0     4973  Policy 0  dikesnet  \n1549                  0     4976  Policy 0  dikesnet  \n1550                  0     4985  Policy 0  dikesnet  \n\n[1551 rows x 53 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A.0_ID flood wave shape</th>\n      <th>A.1_Bmax</th>\n      <th>A.1_Brate</th>\n      <th>A.1_pfail</th>\n      <th>A.2_Bmax</th>\n      <th>A.2_Brate</th>\n      <th>A.2_pfail</th>\n      <th>A.3_Bmax</th>\n      <th>A.3_Brate</th>\n      <th>A.3_pfail</th>\n      <th>...</th>\n      <th>A.3_DikeIncrease 2</th>\n      <th>A.4_DikeIncrease 0</th>\n      <th>A.4_DikeIncrease 1</th>\n      <th>A.4_DikeIncrease 2</th>\n      <th>A.5_DikeIncrease 0</th>\n      <th>A.5_DikeIncrease 1</th>\n      <th>A.5_DikeIncrease 2</th>\n      <th>scenario</th>\n      <th>policy</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>66</td>\n      <td>220.340347</td>\n      <td>1.5</td>\n      <td>0.277751</td>\n      <td>317.625580</td>\n      <td>1.0</td>\n      <td>0.246968</td>\n      <td>114.478228</td>\n      <td>10.0</td>\n      <td>0.552078</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23</td>\n      <td>Policy 0</td>\n      <td>dikesnet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39</td>\n      <td>287.676115</td>\n      <td>1.0</td>\n      <td>0.093811</td>\n      <td>246.091351</td>\n      <td>1.5</td>\n      <td>0.271764</td>\n      <td>101.893796</td>\n      <td>1.0</td>\n      <td>0.429600</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Policy 0</td>\n      <td>dikesnet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50</td>\n      <td>106.756807</td>\n      <td>10.0</td>\n      <td>0.345841</td>\n      <td>333.340514</td>\n      <td>1.5</td>\n      <td>0.745971</td>\n      <td>82.951536</td>\n      <td>1.0</td>\n      <td>0.469837</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>65</td>\n      <td>Policy 0</td>\n      <td>dikesnet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>76</td>\n      <td>56.356797</td>\n      <td>1.5</td>\n      <td>0.189130</td>\n      <td>196.888090</td>\n      <td>10.0</td>\n      <td>0.057171</td>\n      <td>280.790547</td>\n      <td>1.5</td>\n      <td>0.470550</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>125</td>\n      <td>Policy 0</td>\n      <td>dikesnet</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>132</td>\n      <td>298.587312</td>\n      <td>1.5</td>\n      <td>0.000580</td>\n      <td>156.903324</td>\n      <td>1.5</td>\n      <td>0.970702</td>\n      <td>232.692672</td>\n      <td>10.0</td>\n      <td>0.575071</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>155</td>\n      <td>Policy 0</td>\n      <td>dikesnet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1546</th>\n      <td>89</td>\n      <td>46.645355</td>\n      <td>1.0</td>\n      <td>0.751029</td>\n      <td>277.455225</td>\n      <td>1.5</td>\n      <td>0.606332</td>\n      <td>204.774335</td>\n      <td>10.0</td>\n      <td>0.012546</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4966</td>\n      <td>Policy 0</td>\n      <td>dikesnet</td>\n    </tr>\n    <tr>\n      <th>1547</th>\n      <td>62</td>\n      <td>52.666623</td>\n      <td>1.0</td>\n      <td>0.866610</td>\n      <td>52.132103</td>\n      <td>10.0</td>\n      <td>0.671048</td>\n      <td>73.254758</td>\n      <td>10.0</td>\n      <td>0.217036</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4967</td>\n      <td>Policy 0</td>\n      <td>dikesnet</td>\n    </tr>\n    <tr>\n      <th>1548</th>\n      <td>7</td>\n      <td>320.950831</td>\n      <td>1.5</td>\n      <td>0.533701</td>\n      <td>300.887555</td>\n      <td>1.0</td>\n      <td>0.992886</td>\n      <td>134.842915</td>\n      <td>1.0</td>\n      <td>0.166615</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4973</td>\n      <td>Policy 0</td>\n      <td>dikesnet</td>\n    </tr>\n    <tr>\n      <th>1549</th>\n      <td>49</td>\n      <td>260.621182</td>\n      <td>1.5</td>\n      <td>0.756180</td>\n      <td>245.847333</td>\n      <td>1.5</td>\n      <td>0.588074</td>\n      <td>146.423040</td>\n      <td>1.0</td>\n      <td>0.140686</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4976</td>\n      <td>Policy 0</td>\n      <td>dikesnet</td>\n    </tr>\n    <tr>\n      <th>1550</th>\n      <td>35</td>\n      <td>258.320169</td>\n      <td>1.0</td>\n      <td>0.842552</td>\n      <td>57.433710</td>\n      <td>10.0</td>\n      <td>0.934111</td>\n      <td>43.060722</td>\n      <td>1.0</td>\n      <td>0.087416</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4985</td>\n      <td>Policy 0</td>\n      <td>dikesnet</td>\n    </tr>\n  </tbody>\n</table>\n<p>1551 rows × 53 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### A.2.2. Filtering of policy-relevant scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [
    "Due to computational restrictions, only a limited amount of scenarios is used. In this step, scenarios are filtered based on their policy relevance.\n",
    "\n",
    "In the next step, scenarios will be selected using an indicator for scenario diversity.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### A.2.3. Selecting maximally diverse scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is desirable to select maximally diverse scenarios, so that ... ? In this step, maximally diverse scenarios will be selected following the approach of Carlsen et al. (2016)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Normalizing all outcomes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "experiments_of_interest = scenarios['scenario']\n",
    "outcomes_df = pd.DataFrame({k:v[experiments_of_interest] for k,v in outcomes.items()})\n",
    "# normalize outcomes on unit interval to ensure equal weighting of outcomes\n",
    "x = outcomes_df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "normalized_outcomes = pd.DataFrame(x_scaled, columns=outcomes_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:09:14.109010400Z",
     "start_time": "2024-06-12T15:09:13.896491200Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T15:09:16.388344500Z",
     "start_time": "2024-06-12T15:09:16.328459400Z"
    }
   },
   "cell_type": "code",
   "source": "normalized_outcomes.describe()",
   "outputs": [
    {
     "data": {
      "text/plain": "       A.1 Total Costs  A.1_Expected Number of Deaths  A.2 Total Costs  \\\ncount      1551.000000                    1551.000000      1551.000000   \nmean          0.147201                       0.202552         0.281586   \nstd           0.263325                       0.352418         0.274857   \nmin           0.000000                       0.000000         0.000000   \n25%           0.000000                       0.000000         0.026928   \n50%           0.018770                       0.024395         0.206562   \n75%           0.096507                       0.144777         0.519384   \nmax           1.000000                       1.000000         1.000000   \n\n       A.2_Expected Number of Deaths  A.3 Total Costs  \\\ncount                    1551.000000      1551.000000   \nmean                        0.388328         0.340187   \nstd                         0.363970         0.338126   \nmin                         0.000000         0.000000   \n25%                         0.041821         0.000000   \n50%                         0.294506         0.242730   \n75%                         0.662183         0.670450   \nmax                         1.000000         1.000000   \n\n       A.3_Expected Number of Deaths  A.4 Total Costs  \\\ncount                    1551.000000      1551.000000   \nmean                        0.461868         0.051411   \nstd                         0.449401         0.146457   \nmin                         0.000000         0.000000   \n25%                         0.000000         0.000000   \n50%                         0.342232         0.000000   \n75%                         0.964850         0.002960   \nmax                         1.000000         1.000000   \n\n       A.4_Expected Number of Deaths  A.5 Total Costs  \\\ncount                    1551.000000      1551.000000   \nmean                        0.062236         0.026690   \nstd                         0.174582         0.106144   \nmin                         0.000000         0.000000   \n25%                         0.000000         0.000000   \n50%                         0.000000         0.000000   \n75%                         0.003722         0.000000   \nmax                         1.000000         1.000000   \n\n       A.5_Expected Number of Deaths  RfR Total Costs  \\\ncount                    1551.000000           1551.0   \nmean                        0.033302              0.0   \nstd                         0.129834              0.0   \nmin                         0.000000              0.0   \n25%                         0.000000              0.0   \n50%                         0.000000              0.0   \n75%                         0.000000              0.0   \nmax                         1.000000              0.0   \n\n       Expected Evacuation Costs  \ncount                     1551.0  \nmean                         0.0  \nstd                          0.0  \nmin                          0.0  \n25%                          0.0  \n50%                          0.0  \n75%                          0.0  \nmax                          0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A.1 Total Costs</th>\n      <th>A.1_Expected Number of Deaths</th>\n      <th>A.2 Total Costs</th>\n      <th>A.2_Expected Number of Deaths</th>\n      <th>A.3 Total Costs</th>\n      <th>A.3_Expected Number of Deaths</th>\n      <th>A.4 Total Costs</th>\n      <th>A.4_Expected Number of Deaths</th>\n      <th>A.5 Total Costs</th>\n      <th>A.5_Expected Number of Deaths</th>\n      <th>RfR Total Costs</th>\n      <th>Expected Evacuation Costs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1551.000000</td>\n      <td>1551.000000</td>\n      <td>1551.000000</td>\n      <td>1551.000000</td>\n      <td>1551.000000</td>\n      <td>1551.000000</td>\n      <td>1551.000000</td>\n      <td>1551.000000</td>\n      <td>1551.000000</td>\n      <td>1551.000000</td>\n      <td>1551.0</td>\n      <td>1551.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.147201</td>\n      <td>0.202552</td>\n      <td>0.281586</td>\n      <td>0.388328</td>\n      <td>0.340187</td>\n      <td>0.461868</td>\n      <td>0.051411</td>\n      <td>0.062236</td>\n      <td>0.026690</td>\n      <td>0.033302</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.263325</td>\n      <td>0.352418</td>\n      <td>0.274857</td>\n      <td>0.363970</td>\n      <td>0.338126</td>\n      <td>0.449401</td>\n      <td>0.146457</td>\n      <td>0.174582</td>\n      <td>0.106144</td>\n      <td>0.129834</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.026928</td>\n      <td>0.041821</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.018770</td>\n      <td>0.024395</td>\n      <td>0.206562</td>\n      <td>0.294506</td>\n      <td>0.242730</td>\n      <td>0.342232</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.096507</td>\n      <td>0.144777</td>\n      <td>0.519384</td>\n      <td>0.662183</td>\n      <td>0.670450</td>\n      <td>0.964850</td>\n      <td>0.002960</td>\n      <td>0.003722</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating all possible permutations of 4 scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-06-12T15:10:20.280336900Z",
     "start_time": "2024-06-12T15:09:24.031953400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# # DO NOT RUN!!!!!!!!!!! MEMORY ERROR\n",
    "#\n",
    "# import itertools\n",
    "#\n",
    "# n_scen = experiments_of_interest.shape[0]\n",
    "# print(\"Number of scenarios generated:\", n_scen)\n",
    "# indices = range(n_scen)\n",
    "# set_size = 4\n",
    "# combinations = itertools.combinations(indices, set_size)\n",
    "# combinations = list(combinations)\n",
    "# print(\"Number of combinations generated:\", len(combinations))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scenarios generated: 1551\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m set_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4\u001B[39m\n\u001B[0;32m      7\u001B[0m combinations \u001B[38;5;241m=\u001B[39m itertools\u001B[38;5;241m.\u001B[39mcombinations(indices, set_size)\n\u001B[1;32m----> 8\u001B[0m combinations \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcombinations\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of combinations generated:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mlen\u001B[39m(combinations))\n",
      "\u001B[1;31mMemoryError\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculating diversity of each of the combinations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#The following code snippet is adopted from assignment 10 model answers (Kwakkel, 2024)\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "import functools\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import random\n",
    "# the relevant code is in a .py file to esnure parallization works within the notebook\n",
    "from scenario_selection import find_maxdiverse_scenarios\n",
    "import numpy as np\n",
    "\n",
    "# calculate the pairwise distances between the normalized outcomes\n",
    "distances = squareform(pdist(normalized_outcomes.values))\n",
    "\n",
    "cores = os.cpu_count()\n",
    "partial_function = functools.partial(find_maxdiverse_scenarios, distances)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:06:12.961178Z",
     "start_time": "2024-06-12T15:06:12.922708Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sampled_combinations = random.sample(combinations, 100000)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# setup the pool of workers and split the calculations over the set of cores\n",
    "with ProcessPoolExecutor(max_workers=cores) as executor:\n",
    "    worker_data = np.array_split(sampled_combinations, cores)\n",
    "    results = [e for e in executor.map(partial_function, worker_data)]\n",
    "    results = list(itertools.chain.from_iterable(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check most diverse results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #The following code snippet is adopted from assignment 10 model answers (Kwakkel, 2024)\n",
    "#\n",
    "# results.sort(key=lambda entry:entry[0], reverse=True)\n",
    "# most_diverse = results[0]\n",
    "# most_diverse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create scenarios using most diverse scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #The following code snippet is adopted from assignment 10 model answers (Kwakkel, 2024)\n",
    "#\n",
    "# from ema_workbench import Scenario\n",
    "#\n",
    "# selected = experiments.loc[most_diverse[1], ['b', 'delta', 'mean', 'q', 'stdev']]\n",
    "# scenarios = [Scenario(f\"{index}\", **row) for index, row in selected.iterrows()]\n",
    "#\n",
    "# for scenario in scenarios:\n",
    "#     print(scenario)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.3. Generating candidate solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following the scenario selection of the previous step, in this step the Multi-Objective Evolutionary Algorithm (MOEA) epsilon-NSGAII algorithm (Kollat and Reed, 2006)  is used to generate candidate solutions, following the approach of Eker and Kwakkel (2018). + explain how epsilon-NSGAII algorithm works + explain benefits of epsilon-NSGAII algorithm for this case"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating a function to optimize under a certain scenario"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#The following code snippet is adopted from assignment 10 model answers (Kwakkel, 2024)\n",
    "\n",
    "# from ema_workbench import MultiprocessingEvaluator, ema_logging\n",
    "# from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "#\n",
    "# from ema_workbench.em_framework.optimization import (ArchiveLogger,\n",
    "#                                                      EpsilonProgress,\n",
    "#                                                      to_problem, epsilon_nondominated)\n",
    "#\n",
    "# ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "#\n",
    "# def optimize(scenario, nfe, model, epsilons):\n",
    "#     results = []\n",
    "#     convergences = []\n",
    "#     problem = to_problem(model, searchover=\"levers\")\n",
    "#\n",
    "#     with MultiprocessingEvaluator(model) as evaluator:\n",
    "#         for i in range(5):\n",
    "#             convergence_metrics = [\n",
    "#                 ArchiveLogger(\n",
    "#                     \"./archives\",\n",
    "#                     [l.name for l in model.levers],\n",
    "#                     [o.name for o in model.outcomes],\n",
    "#                     base_filename=f\"assignemnt_9_{scenario.name}_seed_{i}.tar.gz\",\n",
    "#                 ),\n",
    "#                 EpsilonProgress(),\n",
    "#             ]\n",
    "#\n",
    "#             result, convergence = evaluator.optimize(nfe=nfe, searchover='levers',\n",
    "#                                          convergence=convergence_metrics,\n",
    "#                                          epsilons=epsilons,\n",
    "#                                          reference=scenario)\n",
    "#\n",
    "#             results.append(result)\n",
    "#             convergences.append(convergence)\n",
    "#\n",
    "#     # merge the results using a non-dominated sort\n",
    "#     reference_set = epsilon_nondominated(results, epsilons, problem)\n",
    "#\n",
    "#     return reference_set, convergences\n",
    "#\n",
    "#\n",
    "# results = []\n",
    "# for scenario in scenarios:\n",
    "#     epsilons = [0.05,]*len(model.outcomes)\n",
    "#\n",
    "#     # note that 100000 nfe is again rather low to ensure proper convergence\n",
    "#     results.append(optimize(scenario, 1e5, model, epsilons))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scenario 1 (reference scenario)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scenario 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scenario 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scenario 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Assess convergence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Combining the pareto set of solutions found for each scenario"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (If you have a very large number of policies, you can choose to down sample your policies in some reasoned way (e.g., picking min and max on each objective, slicing across the pareto front with a particular step size). As a rule of thumb, try to limit the set of policies to at most 50.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from ema_workbench import Policy\n",
    "#\n",
    "# policies = []\n",
    "# for i, (result, _) in enumerate(results):\n",
    "#     result = result.iloc[:, 0:5]\n",
    "#     for j, row in result.iterrows():\n",
    "#         policy = Policy(f'scenario {i} option {j}', **row.to_dict())\n",
    "#         policies.append(policy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Re-evaluate under deep uncertainty\n",
    "Re-evaluate the combined set of solutions over 1000 scenarios sampled using LHS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with MultiprocessingEvaluator(model) as evaluator:\n",
    "#     reeevaluation_results = evaluator.perform_experiments(1000, policies=policies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.4. Tradeoff analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# experiments, outcomes = reeevaluation_results\n",
    "#...."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Signal-to-Noise**\\\n",
    "To quantify the robustness we can use multiple robustness metrices. The first one that we use is the **signal-to-noise ratio**. This is the mean of a dataset divided by the standard deviation. If we want to minimize the outcomes, a low mean and a low standard deviation is preferred."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def signal_to_noise(data, direction):\n",
    "    \"Calculate the signal-to-noise ratio of a dataset with outcome directions (minimize or maximize)\"\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data) \n",
    "    \n",
    "    if direction==ScalarOutcome.MAXIMIZE:\n",
    "        return mean/std\n",
    "    else:\n",
    "        return mean*std "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Empty dictionary to collect the ratio scores of every policy:\n",
    "overall_scores = {}\n",
    "\n",
    "# Loop over all policies and outcomes respectively:\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    scores = {}\n",
    "    \n",
    "    logical = experiments['policy']==policy\n",
    "    \n",
    "    for outcome in model.outcomes:\n",
    "        value  = outcomes[outcome.name][logical]\n",
    "        sn_ratio = s_to_n(value, outcome.kind)\n",
    "        scores[outcome.name] = sn_ratio\n",
    "    overall_scores[policy] = scores\n",
    "    \n",
    "# Create dataframe for visualisation purposes:\n",
    "scores = pd.DataFrame.from_dict(overall_scores).T\n",
    "scores"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualise tradeoffs on a parallel plot:\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "data = scores\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['A.1 Total Costs', 'A.1_Expected Number of Deaths', 'A.2 Total Costs', 'A.2_Expected Number of Deaths', 'A.3 Total Costs', 'A.3_Expected Number of Deaths','RfR Total Costs', 'Expected Evacuation Costs']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "paraxes.invert_axis('A.1 Total Costs')\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Minimax regret**\\\n",
    "Another robustness metric that we use for our analysis is the **minimax regret** metric. This metric computes the regret for each option, then takes the ones with the maximum regret (worst-case), and then chooses the options that minimize this maximum regret. We define regret as the difference between the performance of a policy in a scenario and the performance of the best possible result in that scenario or the reference policy. The province of Gelderland is in favour of policy options with low maximum regret values, because the province is responsible for the safety of her region and pays the policies with government money. So, the province has a high level of risk aversion and therefore this robustness metric is suitable for our analysis.\n",
    "\n",
    "Source: https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1002/2017EF000649"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Empty dictionaries to get the overall and maximum regret:\n",
    "overall_regret = {}\n",
    "max_regret = {}\n",
    "\n",
    "# Loop over all policies and outcomes respectively:\n",
    "for outcome in model.outcomes:\n",
    "    policy_column = experiments['policy']\n",
    "    \n",
    "    # Create DataFrame to store the outcome, name of the policy and scenario:\n",
    "    data = pd.DataFrame({outcome.name: outcomes[outcome.name], \n",
    "                         \"policy\":experiments['policy'],\n",
    "                         \"scenario\":experiments['scenario']})\n",
    "    \n",
    "    # Organise the data:\n",
    "    data = data.pivot(index='scenario', columns='policy')\n",
    "    \n",
    "    # Flatten the hierarchical index from pivoting\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "    \n",
    "    # Take the absolute difference of the maximum across the row and the actual values in the row\n",
    "    outcome_regret = (data.max(axis=1).values[:, np.newaxis] - data).abs()\n",
    "    \n",
    "    overall_regret[outcome.name] = outcome_regret\n",
    "    max_regret[outcome.name] = outcome_regret.max()\n",
    "\n",
    "# Visualise results in a heatmap:\n",
    "max_regret = pd.DataFrame(max_regret)\n",
    "sns.heatmap(max_regret/max_regret.max(), cmap='viridis', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualise tradeoffs on a parallel plot:\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "colors = sns.color_palette()\n",
    "\n",
    "data = max_regret\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['A.1 Total Costs', 'A.1_Expected Number of Deaths', 'A.2 Total Costs', 'A.2_Expected Number of Deaths', 'A.3 Total Costs', 'A.3_Expected Number of Deaths','RfR Total Costs', 'Expected Evacuation Costs']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "for i, (index, row) in enumerate(data.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(index), color=colors[i])\n",
    "paraxes.legend()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
