{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "From Bartholomew & Kwakkel (2020):\n",
    "\n",
    "Multi-scenario many-objective robust decision making Multi-scenario MORDM (Watson and Kasprzyk, 2017) is a further refinement of MORDM. The main contribution of MORDM was the use of a MOEA for finding a set of promising candidate solutions which together capture the key trade-offs amongst competing objec\u0002tives. However, this search uses a single reference scenario, and it is unlikely that solutions that are optimal in a given scenario are also optimally robust. Multi-scenario MORDM (Fig. 1(c)) addresses this by performing a search for candidate strategies for several different refer\u0002ence scenarios. The additional scenarios for which search is performed are selected from regions in the deep uncertainty space where candidate solutions found for the first reference scenario are failing to meet their objectives. So, one performs the four MORDM steps, and based on the insights from scenario discovery, additional scenarios are selected for which search is also performed. The goal of this is to build a more diverse set of policy alternatives which are Pareto optimal under\n",
    "different scenarios. The selection of scenarios after the first MORDM iteration is a crit\u0002ical step in multi-scenario MORDM (Eker and Kwakkel, 2018). Watson and Kasprzyk (2017) suggest picking scenarios based on the scenario discovery results. The number of scenarios to select is left to the analyst. Clearly, if the number of scenarios for which a search is conducted increases, the chance of finding solutions that are robust during the re-evaluation also increases. However, this comes at a sub\u0002stantial computational cost. To assist in balancing comprehensiveness and computational cost, while making scenario selection transparent and reproducible, Eker and Kwakkel (2018) present an approach for finding the most policy relevant and maximally diverse set of scenarios. Policy relevance is defined as scenarios that lead to poor outcomes and the diversity criterion is based on Carlsen et al. (2016)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A. Many-Objective Robust Decision Making with Multi-Scenario Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T07:23:40.845593700Z",
     "start_time": "2024-06-20T07:23:37.585579200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import libraries\n",
    "from ema_workbench import (\n",
    "    Model,\n",
    "    MultiprocessingEvaluator,\n",
    "    ScalarOutcome,\n",
    "    IntegerParameter,\n",
    "    optimize,\n",
    "    Scenario, \n",
    "    save_results,\n",
    "    load_results,\n",
    "    MPIEvaluator,\n",
    "    ema_logging\n",
    ")\n",
    "from ema_workbench.analysis import parcoords\n",
    "from ema_workbench.em_framework.optimization import (ArchiveLogger, EpsilonProgress, rebuild_platypus_population, to_problem, Hypervolume)\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "import functools\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import random\n",
    "from scenario_selection import find_maxdiverse_scenarios\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import itertools"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nelen\\EPA141A\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\__init__.py:101: UserWarning: ipyparallel not installed - IpyparalleEvaluator not available\n",
      "  warnings.warn(\"ipyparallel not installed - IpyparalleEvaluator not available\")\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.1. Problem formulation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:35.343299Z",
     "start_time": "2024-06-19T12:33:35.339602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "# \n",
    "#     model, steps = get_model_for_problem_formulation(3)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.2. Scenario selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is desirable to search for candidate solutions under a variety of scenarios, so that robustness of potential solutions is increased (Eker and Kwakkel, 2018).\n",
    "\n",
    "In this study, our purpose for scenario selection is to find scenarios that potentially lead to solutions that are more robust when\n",
    "the search phase of MORDM is conducted for each of these scenarios. Therefore, among the possible scenario selection criteria\n",
    "listed above, we consider policy relevance and diversity as the\n",
    "relevant ones. Policy-relevance is a problem-specific concept that\n",
    "should reflect the decision-making concerns and preferences. In\n",
    "this study, we choose to define policy-relevance with respect to\n",
    "undesirable scenario conditions specified by the median values of\n",
    "the scenario space. Dividing the scenario space at the median\n",
    "values focuses the diversity analysis on a smaller number of policy-relevant scenarios regardless of their distribution. However, we do\n",
    "not propose this as a general way to define policy relevance. For the\n",
    "diversity criterion, we propose to use the specific diversity\n",
    "maximization method introduced by Carlsen et al. (2016b).\n",
    "\n",
    "Following Eker and Kwakkel (2018), scenario selection is conducted in three steps, namely\n",
    "- 1. Scenario generation;\n",
    "- 2. Filtering of policy-relevant scenarios;\n",
    "- 3. Selecting maximally diverse scenarios."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### A.2.1. Scenario generation and A.2.2. Filtering of policy-relevant scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this step, N scenarios will be generated using randomly sampled values of deep uncertainties and decision levers (Eker and Kwakkel, 2018) ."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Due to computational restrictions, only a limited amount of scenarios is used. In this step, scenarios are filtered based on their policy relevance.\n",
    "\n",
    "In the next step, scenarios will be selected using an indicator for scenario diversity.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:40.762695Z",
     "start_time": "2024-06-19T12:33:40.687631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scenarios, outcomes = load_results(\"./results/scenario_selection.tar.gz\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:41.847446Z",
     "start_time": "2024-06-19T12:33:41.823337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scenarios"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     A.0_ID flood wave shape    A.1_Bmax A.1_Brate  A.1_pfail    A.2_Bmax  \\\n",
       "0                        105  158.533238      10.0   0.537359  315.145762   \n",
       "1                        122  189.698330       1.0   0.682612  299.782340   \n",
       "2                          8  124.406106      10.0   0.564305  188.281947   \n",
       "3                          7   92.494983      10.0   0.695807  141.911870   \n",
       "4                         93   40.537874       1.5   0.712848   49.618879   \n",
       "..                       ...         ...       ...        ...         ...   \n",
       "275                       11  122.316720       1.0   0.572786  114.275576   \n",
       "276                      101  281.165784       1.0   0.693964   42.142980   \n",
       "277                       33   43.823637       1.0   0.643488  303.542361   \n",
       "278                      114   80.309914       1.0   0.542835  179.860698   \n",
       "279                       61   91.994198       1.0   0.583565   51.555592   \n",
       "\n",
       "    A.2_Brate  A.2_pfail    A.3_Bmax A.3_Brate  A.3_pfail  ...  \\\n",
       "0         1.0   0.343249  290.983221       1.0   0.213538  ...   \n",
       "1         1.0   0.708662  176.717249      10.0   0.335554  ...   \n",
       "2         1.5   0.363772  258.363480      10.0   0.238341  ...   \n",
       "3        10.0   0.761783  113.549535      10.0   0.034505  ...   \n",
       "4         1.5   0.547637  205.325470       1.0   0.425226  ...   \n",
       "..        ...        ...         ...       ...        ...  ...   \n",
       "275       1.5   0.569826  139.651981       1.0   0.072716  ...   \n",
       "276      10.0   0.604134  141.749554      10.0   0.238004  ...   \n",
       "277       1.5   0.779226  299.602868      10.0   0.028695  ...   \n",
       "278       1.5   0.340880   92.264076       1.0   0.358026  ...   \n",
       "279      10.0   0.670247  203.122662       1.0   0.099706  ...   \n",
       "\n",
       "     A.3_DikeIncrease 2 A.4_DikeIncrease 0  A.4_DikeIncrease 1  \\\n",
       "0                     0                  0                   0   \n",
       "1                     0                  0                   0   \n",
       "2                     0                  0                   0   \n",
       "3                     0                  0                   0   \n",
       "4                     0                  0                   0   \n",
       "..                  ...                ...                 ...   \n",
       "275                   0                  0                   0   \n",
       "276                   0                  0                   0   \n",
       "277                   0                  0                   0   \n",
       "278                   0                  0                   0   \n",
       "279                   0                  0                   0   \n",
       "\n",
       "     A.4_DikeIncrease 2 A.5_DikeIncrease 0  A.5_DikeIncrease 1  \\\n",
       "0                     0                  0                   0   \n",
       "1                     0                  0                   0   \n",
       "2                     0                  0                   0   \n",
       "3                     0                  0                   0   \n",
       "4                     0                  0                   0   \n",
       "..                  ...                ...                 ...   \n",
       "275                   0                  0                   0   \n",
       "276                   0                  0                   0   \n",
       "277                   0                  0                   0   \n",
       "278                   0                  0                   0   \n",
       "279                   0                  0                   0   \n",
       "\n",
       "    A.5_DikeIncrease 2 scenario    policy     model  \n",
       "0                    0        2  Policy 0  dikesnet  \n",
       "1                    0       33  Policy 0  dikesnet  \n",
       "2                    0       56  Policy 0  dikesnet  \n",
       "3                    0       70  Policy 0  dikesnet  \n",
       "4                    0      117  Policy 0  dikesnet  \n",
       "..                 ...      ...       ...       ...  \n",
       "275                  0     4899  Policy 0  dikesnet  \n",
       "276                  0     4924  Policy 0  dikesnet  \n",
       "277                  0     4934  Policy 0  dikesnet  \n",
       "278                  0     4950  Policy 0  dikesnet  \n",
       "279                  0     4955  Policy 0  dikesnet  \n",
       "\n",
       "[280 rows x 53 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A.0_ID flood wave shape</th>\n",
       "      <th>A.1_Bmax</th>\n",
       "      <th>A.1_Brate</th>\n",
       "      <th>A.1_pfail</th>\n",
       "      <th>A.2_Bmax</th>\n",
       "      <th>A.2_Brate</th>\n",
       "      <th>A.2_pfail</th>\n",
       "      <th>A.3_Bmax</th>\n",
       "      <th>A.3_Brate</th>\n",
       "      <th>A.3_pfail</th>\n",
       "      <th>...</th>\n",
       "      <th>A.3_DikeIncrease 2</th>\n",
       "      <th>A.4_DikeIncrease 0</th>\n",
       "      <th>A.4_DikeIncrease 1</th>\n",
       "      <th>A.4_DikeIncrease 2</th>\n",
       "      <th>A.5_DikeIncrease 0</th>\n",
       "      <th>A.5_DikeIncrease 1</th>\n",
       "      <th>A.5_DikeIncrease 2</th>\n",
       "      <th>scenario</th>\n",
       "      <th>policy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>158.533238</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.537359</td>\n",
       "      <td>315.145762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.343249</td>\n",
       "      <td>290.983221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.213538</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Policy 0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>189.698330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.682612</td>\n",
       "      <td>299.782340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.708662</td>\n",
       "      <td>176.717249</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.335554</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>Policy 0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>124.406106</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.564305</td>\n",
       "      <td>188.281947</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.363772</td>\n",
       "      <td>258.363480</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.238341</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>Policy 0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>92.494983</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.695807</td>\n",
       "      <td>141.911870</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.761783</td>\n",
       "      <td>113.549535</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.034505</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>Policy 0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93</td>\n",
       "      <td>40.537874</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.712848</td>\n",
       "      <td>49.618879</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.547637</td>\n",
       "      <td>205.325470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.425226</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>Policy 0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>11</td>\n",
       "      <td>122.316720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.572786</td>\n",
       "      <td>114.275576</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.569826</td>\n",
       "      <td>139.651981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072716</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4899</td>\n",
       "      <td>Policy 0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>101</td>\n",
       "      <td>281.165784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693964</td>\n",
       "      <td>42.142980</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.604134</td>\n",
       "      <td>141.749554</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.238004</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4924</td>\n",
       "      <td>Policy 0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>33</td>\n",
       "      <td>43.823637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.643488</td>\n",
       "      <td>303.542361</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.779226</td>\n",
       "      <td>299.602868</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.028695</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4934</td>\n",
       "      <td>Policy 0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>114</td>\n",
       "      <td>80.309914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542835</td>\n",
       "      <td>179.860698</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.340880</td>\n",
       "      <td>92.264076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.358026</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4950</td>\n",
       "      <td>Policy 0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>61</td>\n",
       "      <td>91.994198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583565</td>\n",
       "      <td>51.555592</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.670247</td>\n",
       "      <td>203.122662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.099706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4955</td>\n",
       "      <td>Policy 0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 53 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### A.2.3. Selecting maximally diverse scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is desirable to select maximally diverse scenarios, so that ... ? In this step, maximally diverse scenarios will be selected following the approach of Carlsen et al. (2016)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Normalizing all outcomes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "experiments_of_interest = scenarios['scenario']\n",
    "outcomes_df = pd.DataFrame({k:v[experiments_of_interest] for k,v in outcomes.items()})\n",
    "# normalize outcomes on unit interval to ensure equal weighting of outcomes\n",
    "x = outcomes_df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "normalized_outcomes = pd.DataFrame(x_scaled, columns=outcomes_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:48.568183Z",
     "start_time": "2024-06-19T12:33:48.551478Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:48.967383Z",
     "start_time": "2024-06-19T12:33:48.917110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "normalized_outcomes.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       A.1 Total Costs  A.1_Expected Number of Deaths  A.2 Total Costs  \\\n",
       "count       280.000000                     280.000000       280.000000   \n",
       "mean          0.289275                       0.396852         0.212362   \n",
       "std           0.207799                       0.284415         0.197081   \n",
       "min           0.000000                       0.000000         0.000000   \n",
       "25%           0.128633                       0.167743         0.064113   \n",
       "50%           0.230862                       0.332648         0.135318   \n",
       "75%           0.393446                       0.576426         0.310517   \n",
       "max           1.000000                       1.000000         1.000000   \n",
       "\n",
       "       A.2_Expected Number of Deaths  A.3 Total Costs  \\\n",
       "count                     280.000000       280.000000   \n",
       "mean                        0.242325         0.480620   \n",
       "std                         0.217484         0.242927   \n",
       "min                         0.000000         0.000000   \n",
       "25%                         0.071439         0.268359   \n",
       "50%                         0.133737         0.523392   \n",
       "75%                         0.335590         0.691118   \n",
       "max                         1.000000         1.000000   \n",
       "\n",
       "       A.3_Expected Number of Deaths  A.4 Total Costs  \\\n",
       "count                     280.000000       280.000000   \n",
       "mean                        0.672651         0.107348   \n",
       "std                         0.312480         0.226668   \n",
       "min                         0.000000         0.000000   \n",
       "25%                         0.388498         0.000000   \n",
       "50%                         0.741661         0.000000   \n",
       "75%                         0.974567         0.053287   \n",
       "max                         1.000000         1.000000   \n",
       "\n",
       "       A.4_Expected Number of Deaths  A.5 Total Costs  \\\n",
       "count                     280.000000       280.000000   \n",
       "mean                        0.124819         0.068383   \n",
       "std                         0.257644         0.201234   \n",
       "min                         0.000000         0.000000   \n",
       "25%                         0.000000         0.000000   \n",
       "50%                         0.000000         0.000000   \n",
       "75%                         0.065566         0.000000   \n",
       "max                         1.000000         1.000000   \n",
       "\n",
       "       A.5_Expected Number of Deaths  RfR Total Costs  \\\n",
       "count                     280.000000            280.0   \n",
       "mean                        0.078143              0.0   \n",
       "std                         0.227594              0.0   \n",
       "min                         0.000000              0.0   \n",
       "25%                         0.000000              0.0   \n",
       "50%                         0.000000              0.0   \n",
       "75%                         0.000000              0.0   \n",
       "max                         1.000000              0.0   \n",
       "\n",
       "       Expected Evacuation Costs  \n",
       "count                      280.0  \n",
       "mean                         0.0  \n",
       "std                          0.0  \n",
       "min                          0.0  \n",
       "25%                          0.0  \n",
       "50%                          0.0  \n",
       "75%                          0.0  \n",
       "max                          0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A.1 Total Costs</th>\n",
       "      <th>A.1_Expected Number of Deaths</th>\n",
       "      <th>A.2 Total Costs</th>\n",
       "      <th>A.2_Expected Number of Deaths</th>\n",
       "      <th>A.3 Total Costs</th>\n",
       "      <th>A.3_Expected Number of Deaths</th>\n",
       "      <th>A.4 Total Costs</th>\n",
       "      <th>A.4_Expected Number of Deaths</th>\n",
       "      <th>A.5 Total Costs</th>\n",
       "      <th>A.5_Expected Number of Deaths</th>\n",
       "      <th>RfR Total Costs</th>\n",
       "      <th>Expected Evacuation Costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>280.0</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.289275</td>\n",
       "      <td>0.396852</td>\n",
       "      <td>0.212362</td>\n",
       "      <td>0.242325</td>\n",
       "      <td>0.480620</td>\n",
       "      <td>0.672651</td>\n",
       "      <td>0.107348</td>\n",
       "      <td>0.124819</td>\n",
       "      <td>0.068383</td>\n",
       "      <td>0.078143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.207799</td>\n",
       "      <td>0.284415</td>\n",
       "      <td>0.197081</td>\n",
       "      <td>0.217484</td>\n",
       "      <td>0.242927</td>\n",
       "      <td>0.312480</td>\n",
       "      <td>0.226668</td>\n",
       "      <td>0.257644</td>\n",
       "      <td>0.201234</td>\n",
       "      <td>0.227594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.167743</td>\n",
       "      <td>0.064113</td>\n",
       "      <td>0.071439</td>\n",
       "      <td>0.268359</td>\n",
       "      <td>0.388498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.230862</td>\n",
       "      <td>0.332648</td>\n",
       "      <td>0.135318</td>\n",
       "      <td>0.133737</td>\n",
       "      <td>0.523392</td>\n",
       "      <td>0.741661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.393446</td>\n",
       "      <td>0.576426</td>\n",
       "      <td>0.310517</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>0.691118</td>\n",
       "      <td>0.974567</td>\n",
       "      <td>0.053287</td>\n",
       "      <td>0.065566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating all possible permutations of 4 scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:52.858132Z",
     "start_time": "2024-06-19T12:33:52.855082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# n_scen = experiments_of_interest.shape[0]\n",
    "# print(\"Number of scenarios generated:\", n_scen)\n",
    "# indices = range(n_scen)\n",
    "# set_size = 4\n",
    "# combinations = itertools.combinations(indices, set_size)\n",
    "# combinations = list(combinations)\n",
    "# print(\"Number of combinations generated:\", len(combinations))"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculating diversity of each of the combinations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# #The following code snippet is adopted from assignment 10 model answers (Kwakkel, 2024)\n",
    "# \n",
    "# # calculate the pairwise distances between the normalized outcomes\n",
    "# distances = squareform(pdist(normalized_outcomes.values))\n",
    "# \n",
    "# cores = os.cpu_count()\n",
    "# partial_function = functools.partial(find_maxdiverse_scenarios, distances)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:53.699839Z",
     "start_time": "2024-06-19T12:33:53.696241Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:54.193692Z",
     "start_time": "2024-06-19T12:33:54.187613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sampled_combinations = random.sample(combinations, 50000)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:54.566297Z",
     "start_time": "2024-06-19T12:33:54.563861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # setup the pool of workers and split the calculations over the set of cores\n",
    "# with ProcessPoolExecutor(max_workers=cores) as executor:\n",
    "#     worker_data = np.array_split(sampled_combinations, cores)\n",
    "#     results = [e for e in executor.map(partial_function, worker_data)]\n",
    "#     results = list(itertools.chain.from_iterable(results))"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check most diverse results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# # #The following code snippet is adopted from assignment 10 model answers (Kwakkel, 2024)\n",
    "# #\n",
    "# results.sort(key=lambda entry:entry[0], reverse=True)\n",
    "# most_diverse = results[0]\n",
    "# most_diverse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:55.888443Z",
     "start_time": "2024-06-19T12:33:55.885733Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Output is: ([1.699086703509649], array([ 67, 182, 257, 264]))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create scenarios using most diverse scenarios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:33:59.666855Z",
     "start_time": "2024-06-19T12:33:59.662395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scenario_inputs = [i for i in scenarios.keys()]"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:34:01.035835Z",
     "start_time": "2024-06-19T12:34:01.032066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scenario_inputs = scenario_inputs[0:19]"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:34:01.444218Z",
     "start_time": "2024-06-19T12:34:01.439904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(scenario_inputs)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A.0_ID flood wave shape', 'A.1_Bmax', 'A.1_Brate', 'A.1_pfail', 'A.2_Bmax', 'A.2_Brate', 'A.2_pfail', 'A.3_Bmax', 'A.3_Brate', 'A.3_pfail', 'A.4_Bmax', 'A.4_Brate', 'A.4_pfail', 'A.5_Bmax', 'A.5_Brate', 'A.5_pfail', 'discount rate 0', 'discount rate 1', 'discount rate 2']\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:34:03.695842Z",
     "start_time": "2024-06-19T12:34:03.680861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#The following code snippet is adopted from assignment 10 model answers (Kwakkel, 2024)\n",
    "\n",
    "# select columns which are uncertainties\n",
    "selected = scenarios[scenario_inputs]\n",
    "# most_diverse = ([1.699086703509649], np.array([ 67, 182, 257, 264])) # follows from analysis above\n",
    "indices = [67, 182, 257, 264]\n",
    "# select only these four scenarios\n",
    "selected = selected.loc[indices]\n",
    "# define EMA scenario\n",
    "scenarios = [Scenario(f\"{index}\", **row) for index, row in selected.iterrows()]\n",
    "# print scenarios\n",
    "for scenario in scenarios:\n",
    "    print(scenario)\n",
    "    print(\"\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario({'A.0_ID flood wave shape': 44.0, 'A.1_Bmax': 286.64599121879684, 'A.1_Brate': 10.0, 'A.1_pfail': 0.707203279180436, 'A.2_Bmax': 70.7535283550602, 'A.2_Brate': 10.0, 'A.2_pfail': 0.1821768730444873, 'A.3_Bmax': 71.83446711156625, 'A.3_Brate': 10.0, 'A.3_pfail': 0.4088389187038367, 'A.4_Bmax': 232.45895828113493, 'A.4_Brate': 10.0, 'A.4_pfail': 0.0250796789063121, 'A.5_Bmax': 309.2326438335386, 'A.5_Brate': 1.5, 'A.5_pfail': 0.1372716851642172, 'discount rate 0': 1.5, 'discount rate 1': 3.5, 'discount rate 2': 3.5})\n",
      "\n",
      "\n",
      "Scenario({'A.0_ID flood wave shape': 45.0, 'A.1_Bmax': 39.355371708328974, 'A.1_Brate': 1.5, 'A.1_pfail': 0.5550709615297844, 'A.2_Bmax': 168.33572498519675, 'A.2_Brate': 10.0, 'A.2_pfail': 0.6160894780908688, 'A.3_Bmax': 204.51182823914576, 'A.3_Brate': 1.5, 'A.3_pfail': 0.3190998245752335, 'A.4_Bmax': 188.4745656476624, 'A.4_Brate': 1.5, 'A.4_pfail': 0.4240709667157523, 'A.5_Bmax': 334.2027988375561, 'A.5_Brate': 1.5, 'A.5_pfail': 0.03716758608412, 'discount rate 0': 3.5, 'discount rate 1': 1.5, 'discount rate 2': 1.5})\n",
      "\n",
      "\n",
      "Scenario({'A.0_ID flood wave shape': 16.0, 'A.1_Bmax': 222.0341659919933, 'A.1_Brate': 10.0, 'A.1_pfail': 0.6639915782676712, 'A.2_Bmax': 165.14518948511326, 'A.2_Brate': 1.0, 'A.2_pfail': 0.2527228083499854, 'A.3_Bmax': 255.5592124996132, 'A.3_Brate': 1.0, 'A.3_pfail': 0.1788182835745426, 'A.4_Bmax': 118.05485826519607, 'A.4_Brate': 1.0, 'A.4_pfail': 0.4683673004257024, 'A.5_Bmax': 89.12033467961132, 'A.5_Brate': 1.5, 'A.5_pfail': 0.3768510853576577, 'discount rate 0': 3.5, 'discount rate 1': 3.5, 'discount rate 2': 2.5})\n",
      "\n",
      "\n",
      "Scenario({'A.0_ID flood wave shape': 14.0, 'A.1_Bmax': 99.07216969392977, 'A.1_Brate': 1.0, 'A.1_pfail': 0.5309220953439172, 'A.2_Bmax': 119.92874569144576, 'A.2_Brate': 10.0, 'A.2_pfail': 0.5577131447206267, 'A.3_Bmax': 137.82139768471328, 'A.3_Brate': 10.0, 'A.3_pfail': 0.26562814946924, 'A.4_Bmax': 301.9344988371227, 'A.4_Brate': 10.0, 'A.4_pfail': 0.0937777657817035, 'A.5_Bmax': 213.92725299628063, 'A.5_Brate': 1.5, 'A.5_pfail': 0.1643871655702195, 'discount rate 0': 3.5, 'discount rate 1': 4.5, 'discount rate 2': 2.5})\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:34:06.418726Z",
     "start_time": "2024-06-19T12:34:05.492645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model, steps = get_model_for_problem_formulation(3)\n",
    "\n",
    "reference_values = {\n",
    "    \"Bmax\": 175,\n",
    "    \"Brate\": 1.5,\n",
    "    \"pfail\": 0.5,\n",
    "    \"discount rate 0\": 3.5,\n",
    "    \"discount rate 1\": 3.5,\n",
    "    \"discount rate 2\": 3.5,\n",
    "    \"ID flood wave shape\": 4,\n",
    "}\n",
    "scen1 = {}\n",
    "\n",
    "for key in model.uncertainties:\n",
    "    name_split = key.name.split(\"_\")\n",
    "\n",
    "    if len(name_split) == 1:\n",
    "        scen1.update({key.name: reference_values[key.name]})\n",
    "\n",
    "    else:\n",
    "        scen1.update({key.name: reference_values[name_split[1]]})\n",
    "\n",
    "# define reference scenario\n",
    "ref_scenario = Scenario(\"reference\", **scen1)\n",
    "# add reference scenario to scenarios\n",
    "scenarios.append(ref_scenario)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:34:07.169181Z",
     "start_time": "2024-06-19T12:34:07.165838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in scenarios: \n",
    "    print(i)\n",
    "    print('\\n')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario({'A.0_ID flood wave shape': 44.0, 'A.1_Bmax': 286.64599121879684, 'A.1_Brate': 10.0, 'A.1_pfail': 0.707203279180436, 'A.2_Bmax': 70.7535283550602, 'A.2_Brate': 10.0, 'A.2_pfail': 0.1821768730444873, 'A.3_Bmax': 71.83446711156625, 'A.3_Brate': 10.0, 'A.3_pfail': 0.4088389187038367, 'A.4_Bmax': 232.45895828113493, 'A.4_Brate': 10.0, 'A.4_pfail': 0.0250796789063121, 'A.5_Bmax': 309.2326438335386, 'A.5_Brate': 1.5, 'A.5_pfail': 0.1372716851642172, 'discount rate 0': 1.5, 'discount rate 1': 3.5, 'discount rate 2': 3.5})\n",
      "\n",
      "\n",
      "Scenario({'A.0_ID flood wave shape': 45.0, 'A.1_Bmax': 39.355371708328974, 'A.1_Brate': 1.5, 'A.1_pfail': 0.5550709615297844, 'A.2_Bmax': 168.33572498519675, 'A.2_Brate': 10.0, 'A.2_pfail': 0.6160894780908688, 'A.3_Bmax': 204.51182823914576, 'A.3_Brate': 1.5, 'A.3_pfail': 0.3190998245752335, 'A.4_Bmax': 188.4745656476624, 'A.4_Brate': 1.5, 'A.4_pfail': 0.4240709667157523, 'A.5_Bmax': 334.2027988375561, 'A.5_Brate': 1.5, 'A.5_pfail': 0.03716758608412, 'discount rate 0': 3.5, 'discount rate 1': 1.5, 'discount rate 2': 1.5})\n",
      "\n",
      "\n",
      "Scenario({'A.0_ID flood wave shape': 16.0, 'A.1_Bmax': 222.0341659919933, 'A.1_Brate': 10.0, 'A.1_pfail': 0.6639915782676712, 'A.2_Bmax': 165.14518948511326, 'A.2_Brate': 1.0, 'A.2_pfail': 0.2527228083499854, 'A.3_Bmax': 255.5592124996132, 'A.3_Brate': 1.0, 'A.3_pfail': 0.1788182835745426, 'A.4_Bmax': 118.05485826519607, 'A.4_Brate': 1.0, 'A.4_pfail': 0.4683673004257024, 'A.5_Bmax': 89.12033467961132, 'A.5_Brate': 1.5, 'A.5_pfail': 0.3768510853576577, 'discount rate 0': 3.5, 'discount rate 1': 3.5, 'discount rate 2': 2.5})\n",
      "\n",
      "\n",
      "Scenario({'A.0_ID flood wave shape': 14.0, 'A.1_Bmax': 99.07216969392977, 'A.1_Brate': 1.0, 'A.1_pfail': 0.5309220953439172, 'A.2_Bmax': 119.92874569144576, 'A.2_Brate': 10.0, 'A.2_pfail': 0.5577131447206267, 'A.3_Bmax': 137.82139768471328, 'A.3_Brate': 10.0, 'A.3_pfail': 0.26562814946924, 'A.4_Bmax': 301.9344988371227, 'A.4_Brate': 10.0, 'A.4_pfail': 0.0937777657817035, 'A.5_Bmax': 213.92725299628063, 'A.5_Brate': 1.5, 'A.5_pfail': 0.1643871655702195, 'discount rate 0': 3.5, 'discount rate 1': 4.5, 'discount rate 2': 2.5})\n",
      "\n",
      "\n",
      "Scenario({'discount rate 0': 3.5, 'discount rate 1': 3.5, 'discount rate 2': 3.5, 'A.0_ID flood wave shape': 4, 'A.1_Bmax': 175, 'A.1_pfail': 0.5, 'A.1_Brate': 1.5, 'A.2_Bmax': 175, 'A.2_pfail': 0.5, 'A.2_Brate': 1.5, 'A.3_Bmax': 175, 'A.3_pfail': 0.5, 'A.3_Brate': 1.5, 'A.4_Bmax': 175, 'A.4_pfail': 0.5, 'A.4_Brate': 1.5, 'A.5_Bmax': 175, 'A.5_pfail': 0.5, 'A.5_Brate': 1.5})\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.3. Generating candidate solutions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following the scenario selection of the previous step, in this step the Multi-Objective Evolutionary Algorithm (MOEA) epsilon-NSGAII algorithm (Kollat and Reed, 2006)  is used to generate candidate solutions, following the approach of Eker and Kwakkel (2018). + explain how epsilon-NSGAII algorithm works + explain benefits of epsilon-NSGAII algorithm for this case"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating a function to optimize under a certain scenario"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    # define the model and steps\n",
    "    model, steps = get_model_for_problem_formulation(3)\n",
    "\n",
    "    def optimize(model, scenario, nfe, epsilons, seed_nr):\n",
    "        results = []\n",
    "        convergences = []\n",
    "        with MultiprocessingEvaluator(model) as evaluator:\n",
    "            for i in range(seed_nr):\n",
    "                convergence_metrics = [ArchiveLogger(\n",
    "                    \"./results/\",\n",
    "                    [l.name for l in model.levers],\n",
    "                    [o.name for o in model.outcomes],\n",
    "                    base_filename=f\"optimization_3_{scenario.name}_seed_{i}.tar.gz\"),\n",
    "                    EpsilonProgress(),\n",
    "                ]\n",
    "\n",
    "                result, convergence = evaluator.optimize(nfe=nfe, searchover='levers',\n",
    "                                                         convergence=convergence_metrics,\n",
    "                                                         epsilons=epsilons,\n",
    "                                                         reference=scenario)\n",
    "                results.append(result)\n",
    "                convergences.append(convergence)\n",
    "\n",
    "        return results, convergences\n",
    "\n",
    "    optimizations = []\n",
    "    fig, ax = plt.subplots(ncols=1)\n",
    "    legend_items = []\n",
    "    colors = sns.color_palette()\n",
    "    for scenario in scenarios:\n",
    "        if scenario.name == 'reference':\n",
    "            color = colors[0]\n",
    "            legend_items.append((mpl.lines.Line2D([0,0], [1,1], c=color), scenario.name))\n",
    "            # epsilons = [1e5, ] * len(model.outcomes)\n",
    "            epsilons = [1e4, 0.01, 1e4, 0.01, 1e4, 0.01, 1e4, 0.01, 1e4, 0.01, 1e4, 1e4]\n",
    "            optimizer = optimize(model, scenario, 100000, epsilons, 3)\n",
    "            optimizations.append(optimizer)\n",
    "            convergences = optimizer[1]\n",
    "            for convergence in convergences:\n",
    "                ax.plot(convergence.nfe, convergence.epsilon_progress, c=color)\n",
    "\n",
    "    artists, labels = zip(*legend_items)\n",
    "    fig.legend(artists, labels, bbox_to_anchor=(1.15, 0.9))\n",
    "    ax.set_xlabel(\"Number of functional evaluations\")\n",
    "    ax.set_ylabel(r\"$\\epsilon$ progress\")\n",
    "    plt.title(f\"Convergence of epsilon for reference scenario\")\n",
    "    plt.savefig(f'./results/optimization_3_{scenario.name}_convergence.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Convergence"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T20:20:43.204198Z",
     "start_time": "2024-06-19T20:20:43.173683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_convergence(seed_nr=3, optimizer='opt150'): \n",
    "    \"\"\"\n",
    "    This function visualises the epsilon progress over the number of functional evaluations, \n",
    "    evaluating the convergence of the epsilon progress for both scenarios and seeds.\n",
    "    \"\"\"\n",
    "    # figure settings\n",
    "    fig, ax = plt.subplots(ncols=1)\n",
    "    legend_items = []\n",
    "    colors = sns.color_palette()\n",
    "    scenario_nr = 0\n",
    "    scenarios = [\"reference\", \"67\", \"182\", \"257\", \"264\"]\n",
    "    # for each scenario\n",
    "    for scenario in scenarios: \n",
    "        # one color per scenario\n",
    "        color = colors[scenario_nr]\n",
    "        # index scenario number added by 1\n",
    "        scenario_nr += 1\n",
    "        # add scenario to legend\n",
    "        legend_items.append((mpl.lines.Line2D([0,0], [1,1], c=color), scenario))\n",
    "        # for each seed\n",
    "        for seed in range(seed_nr):\n",
    "            # import convergence metrics\n",
    "            convergence_metrics = pd.read_csv(f\"./results/{optimizer}/optimization_3_{scenario}_seed_{seed}_convergence.csv\")\n",
    "            # add to figure\n",
    "            ax.plot(convergence_metrics.nfe, convergence_metrics.epsilon_progress, c=color)\n",
    "    # display figure    \n",
    "    artists, labels = zip(*legend_items)\n",
    "    fig.legend(artists, labels, bbox_to_anchor=(1.15, 0.9))\n",
    "    ax.set_xlabel(\"Number of functional evaluations\")\n",
    "    ax.set_ylabel(r\"$\\epsilon$ progress\")\n",
    "    plt.title(f\"Convergence of epsilon\")\n",
    "    plt.savefig(f'./results/opt150/optimization_3_convergence.png', bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "show_convergence(3, 'opt150')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def analyse_solutions(optimizer='opt150', scenario='reference', seed_nr=3): \n",
    "    \"\"\"\n",
    "    This function analyses the solutions generated by the optimization. \n",
    "    \"\"\"\n",
    "    all_archives = []\n",
    "    for seed in range(seed_nr):\n",
    "         # import data through archive logger\n",
    "        archive = ArchiveLogger.load_archives(f\"./results/{optimizer}/optimization_3_{scenario}_seed_{seed}.tar.gz\")  \n",
    "        archive = archive[max(archive.keys())]\n",
    "        archive = archive.iloc[:, 1:(len(archive.columns))]\n",
    "        all_archives.append(archive)\n",
    "    \n",
    "    for i, (result, color) in enumerate(zip(all_archives, sns.color_palette())):\n",
    "        outcomes = result.loc[:, ['A.1 Total Costs', 'A.1_Expected Number of Deaths', 'A.2 Total Costs', 'A.2_Expected Number of Deaths', 'A.3 Total Costs', 'A.3_Expected Number of Deaths','RfR Total Costs', 'Expected Evacuation Costs']]\n",
    "        axes.plot(outcomes, label='results {}'.format(i))\n",
    "             \n",
    "        outcomes = archive.loc[:, ['A.1 Total Costs', 'A.1_Expected Number of Deaths', 'A.2 Total Costs', 'A.2_Expected Number of Deaths', 'A.3 Total Costs', 'A.3_Expected Number of Deaths','RfR Total Costs', 'Expected Evacuation Costs']]\n",
    " \n",
    " \n",
    " \n",
    "        \n",
    "        limits = parcoords.get_limits(data)\n",
    "\n",
    "        limits.loc[0, ['A.1_Expected Number of Deaths','A.2_Expected Number of Deaths','A.3_Expected Number of Deaths',]] = 1\n",
    "        limits.loc[0, 'max_P'] = 6 # max over results based on quick inspection not shown here\n",
    "        limits.loc[0, 'utility'] = 1 # max over results based on quick inspection not shown here\n",
    "        limits.loc[1, :] = 0\n",
    "        \n",
    "        axes = parcoords.ParallelAxes(limits)\n",
    "        \n",
    "\n",
    "            \n",
    "        axes.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scenario 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scenario 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scenario 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scenario 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Combining the pareto set of solutions found for each scenario"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (If you have a very large number of policies, you can choose to down sample your policies in some reasoned way (e.g., picking min and max on each objective, slicing across the pareto front with a particular step size). As a rule of thumb, try to limit the set of policies to at most 50.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from ema_workbench import Policy\n",
    "#\n",
    "# policies = []\n",
    "# for i, (result, _) in enumerate(results):\n",
    "#     result = result.iloc[:, 0:5]\n",
    "#     for j, row in result.iterrows():\n",
    "#         policy = Policy(f'scenario {i} option {j}', **row.to_dict())\n",
    "#         policies.append(policy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Re-evaluate under deep uncertainty\n",
    "Re-evaluate the combined set of solutions over 1000 scenarios sampled using LHS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with MultiprocessingEvaluator(model) as evaluator:\n",
    "#     reeevaluation_results = evaluator.perform_experiments(1000, policies=policies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.4. Tradeoff analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# experiments, outcomes = reeevaluation_results\n",
    "#...."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Signal-to-Noise**\\\n",
    "To quantify the robustness we can use multiple robustness metrices. The first one that we use is the **signal-to-noise ratio**. This is the mean of a dataset divided by the standard deviation. If we want to minimize the outcomes, a low mean and a low standard deviation is preferred."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:43:34.630857Z",
     "start_time": "2024-06-14T11:43:34.623077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def signal_to_noise(data, direction):\n",
    "    \"Calculate the signal-to-noise ratio of a dataset with outcome directions (minimize or maximize)\"\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data) \n",
    "    \n",
    "    if direction==ScalarOutcome.MAXIMIZE:\n",
    "        return mean/std\n",
    "    else:\n",
    "        return mean*std "
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:43:37.752185Z",
     "start_time": "2024-06-14T11:43:37.671542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Empty dictionary to collect the ratio scores of every policy:\n",
    "overall_scores = {}\n",
    "\n",
    "# Loop over all policies and outcomes respectively:\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    scores = {}\n",
    "    \n",
    "    logical = experiments['policy']==policy\n",
    "    \n",
    "    for outcome in model.outcomes:\n",
    "        value  = outcomes[outcome.name][logical]\n",
    "        sn_ratio = s_to_n(value, outcome.kind)\n",
    "        scores[outcome.name] = sn_ratio\n",
    "    overall_scores[policy] = scores\n",
    "    \n",
    "# Create dataframe for visualisation purposes:\n",
    "scores = pd.DataFrame.from_dict(overall_scores).T\n",
    "scores"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[53], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m overall_scores \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Loop over all policies and outcomes respectively:\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m policy \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39munique(\u001B[43mexperiments\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpolicy\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m      6\u001B[0m     scores \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      8\u001B[0m     logical \u001B[38;5;241m=\u001B[39m experiments[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpolicy\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m==\u001B[39mpolicy\n",
      "\u001B[0;31mNameError\u001B[0m: name 'experiments' is not defined"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualise tradeoffs on a parallel plot:\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "data = scores\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['A.1 Total Costs', 'A.1_Expected Number of Deaths', 'A.2 Total Costs', 'A.2_Expected Number of Deaths', 'A.3 Total Costs', 'A.3_Expected Number of Deaths','RfR Total Costs', 'Expected Evacuation Costs']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "paraxes.plot(data)\n",
    "paraxes.invert_axis('A.1 Total Costs')\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Minimax regret**\\\n",
    "Another robustness metric that we use for our analysis is the **minimax regret** metric. This metric computes the regret for each option, then takes the ones with the maximum regret (worst-case), and then chooses the options that minimize this maximum regret. We define regret as the difference between the performance of a policy in a scenario and the performance of the best possible result in that scenario or the reference policy. The province of Gelderland is in favour of policy options with low maximum regret values, because the province is responsible for the safety of her region and pays the policies with government money. So, the province has a high level of risk aversion and therefore this robustness metric is suitable for our analysis.\n",
    "\n",
    "Source: https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1002/2017EF000649"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Empty dictionaries to get the overall and maximum regret:\n",
    "overall_regret = {}\n",
    "max_regret = {}\n",
    "\n",
    "# Loop over all policies and outcomes respectively:\n",
    "for outcome in model.outcomes:\n",
    "    policy_column = experiments['policy']\n",
    "    \n",
    "    # Create DataFrame to store the outcome, name of the policy and scenario:\n",
    "    data = pd.DataFrame({outcome.name: outcomes[outcome.name], \n",
    "                         \"policy\":experiments['policy'],\n",
    "                         \"scenario\":experiments['scenario']})\n",
    "    \n",
    "    # Organise the data:\n",
    "    data = data.pivot(index='scenario', columns='policy')\n",
    "    \n",
    "    # Flatten the hierarchical index from pivoting\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "    \n",
    "    # Take the absolute difference of the maximum across the row and the actual values in the row\n",
    "    outcome_regret = (data.max(axis=1).values[:, np.newaxis] - data).abs()\n",
    "    \n",
    "    overall_regret[outcome.name] = outcome_regret\n",
    "    max_regret[outcome.name] = outcome_regret.max()\n",
    "\n",
    "# Visualise results in a heatmap:\n",
    "max_regret = pd.DataFrame(max_regret)\n",
    "sns.heatmap(max_regret/max_regret.max(), cmap='viridis', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualise tradeoffs on a parallel plot:\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "colors = sns.color_palette()\n",
    "\n",
    "data = max_regret\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['A.1 Total Costs', 'A.1_Expected Number of Deaths', 'A.2 Total Costs', 'A.2_Expected Number of Deaths', 'A.3 Total Costs', 'A.3_Expected Number of Deaths','RfR Total Costs', 'Expected Evacuation Costs']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "for i, (index, row) in enumerate(data.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(index), color=colors[i])\n",
    "paraxes.legend()\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
